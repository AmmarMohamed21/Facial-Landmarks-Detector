{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WP7CvDDnd4lV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ammar\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
            "  \"class\": algorithms.Blowfish,\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "import ast\n",
        "import os\n",
        "from preprocessor import *\n",
        "from feature_extractor import *\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "import math\n",
        "import time\n",
        "import joblib\n",
        "from landmarks_detector import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#already tried\n",
        "#hog sift, alpha 1000 sift 10000\n",
        "#hog hog sift, alpha 10000 alpha 10000 sift 30000 the best so far\n",
        "\n",
        "#hog 10000 hog 10000 sift 10000 \n",
        "#hog 10000 hog 10000 sift 100000 0.07 not tried on new dataset\n",
        "#hog hog sift, alpha 10000 alpha 10000 sift 20000 test results not printed\n",
        "#hog hog sift, alpha 10000 alpha 10000 sift 30000 \n",
        "#hog hog sift, alpha 10000 alpha 10000 sift 50000\n",
        "#hog hog sift, alpha 10000 alpha 10000 sift 40000 best so far\n",
        "\n",
        "#to be tried \n",
        "\n",
        "#hog hog sift, alpha 3000 alpha 3000 sift 40000\n",
        "#hog hog sift, alpha 7000 alpha 7000 sift 40000 done\n",
        "#hog hog sift, alpha 5000 alpha 5000 sift 40000 now\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "featuresUsed = [FeatureType.HOG, FeatureType.HOG, FeatureType.SIFT]\n",
        "L = 3\n",
        "alphas = [10000,3000,40000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1\n",
            "\n",
            "Iteration 1 Error after sampling: 0.3750703748258848\n",
            "\n",
            "K:  1\n",
            "Feature Extraction...\n",
            "HOG\n",
            "Training regressor...\n",
            "Alpha:  10000\n",
            "Error after iteration l= 1 , regressor k= 1 :  0.2896039327247731\n",
            "K:  2\n",
            "Feature Extraction...\n",
            "HOG\n",
            "Training regressor...\n",
            "Alpha:  10000\n",
            "Error after iteration l= 1 , regressor k= 2 :  0.24676964584543162\n",
            "K:  3\n",
            "Feature Extraction...\n",
            "HOG\n",
            "Training regressor...\n",
            "Alpha:  10000\n",
            "Error after iteration l= 1 , regressor k= 3 :  0.2213447726241388\n",
            "Updating distributions...\n",
            "Iteration 2\n",
            "\n",
            "Iteration 2 Error after sampling: 0.18079189800442874\n",
            "\n",
            "K:  1\n",
            "Feature Extraction...\n",
            "HOG\n",
            "Training regressor...\n",
            "Alpha:  3000\n",
            "Error after iteration l= 2 , regressor k= 1 :  0.1443048124113655\n",
            "K:  2\n",
            "Feature Extraction...\n",
            "HOG\n",
            "Training regressor...\n",
            "Alpha:  3000\n",
            "Error after iteration l= 2 , regressor k= 2 :  0.12984304820618575\n",
            "K:  3\n",
            "Feature Extraction...\n",
            "HOG\n",
            "Training regressor...\n",
            "Alpha:  3000\n",
            "Error after iteration l= 2 , regressor k= 3 :  0.12226133867737361\n",
            "Updating distributions...\n",
            "Iteration 3\n",
            "\n",
            "Iteration 3 Error after sampling: 0.13515344854474445\n",
            "\n",
            "K:  1\n",
            "Feature Extraction...\n",
            "Using SIFT\n",
            "standardization\n",
            "PCA\n",
            "PCA components:  2176\n",
            "Training regressor...\n",
            "Alpha:  40000\n",
            "Error after iteration l= 3 , regressor k= 1 :  0.08298877964270472\n",
            "K:  2\n",
            "Feature Extraction...\n",
            "Using SIFT\n",
            "standardization\n",
            "PCA\n",
            "PCA components:  2176\n",
            "Training regressor...\n",
            "Alpha:  40000\n",
            "Error after iteration l= 3 , regressor k= 2 :  0.0619285884760711\n",
            "K:  3\n",
            "Feature Extraction...\n",
            "Using SIFT\n",
            "standardization\n",
            "PCA\n",
            "PCA components:  2176\n",
            "Training regressor...\n",
            "Alpha:  40000\n",
            "Error after iteration l= 3 , regressor k= 3 :  0.055410862997609375\n",
            "Test Accuracy on lfpw images: 0.06331979447871904\n",
            "\n",
            "Test Accuracy on 300w images: 0.10332019471891982\n",
            "\n",
            "Test Accuracy on helen images: 0.06397153174903211\n",
            "\n",
            "Test Accuracy on ibug_test images: 0.15697777009869426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "detector = LandmarksDetector()\n",
        "regressors, scalarmodels, pca_models, x_bar_initial = detector.train('combined2/train.csv', 'combined2/trainset/', featuresUsed=featuresUsed, L=L, alphas=alphas)\n",
        "\n",
        "detector.calculateTestAccuracy('lfpw/croppedlfpw_test.csv','lfpw/croppedlfpw/testset/', x_bar_initial, regressors, featuresUsed, pca_models, scalarmodels)\n",
        "detector.calculateTestAccuracy('300w/cropped300w_test.csv','300w/cropped300w/testset/', x_bar_initial, regressors, featuresUsed, pca_models, scalarmodels)\n",
        "detector.calculateTestAccuracy('helen/croppedhelen_test.csv','helen/croppedhelen/testset/', x_bar_initial, regressors, featuresUsed, pca_models, scalarmodels)\n",
        "detector.calculateTestAccuracy('ibug_test/croppedibug_test.csv','ibug_test/testset/', x_bar_initial, regressors, featuresUsed, pca_models, scalarmodels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CropAndResizeDataset(\"lfpw/lfpw_train.csv\", \"lfpw/trainset/\", \"lfpw/cropped2lfpw/trainset/\", \"lfpw/cropped2lfpw_train.csv\")\n",
        "# CropAndResizeDataset(\"lfpw/lfpw_test.csv\", \"lfpw/testset/\", \"lfpw/cropped2lfpw/testset/\", \"lfpw/cropped2lfpw_test.csv\")\n",
        "\n",
        "# CropAndResizeDataset(\"300w/300w_train.csv\", \"300w/trainset/\", \"300w/cropped2300w/trainset/\", \"300w/cropped2300w_train.csv\")\n",
        "# CropAndResizeDataset(\"300w/300w_test.csv\", \"300w/testset/\", \"300w/cropped2300w/testset/\", \"300w/cropped2300w_test.csv\")\n",
        "                     \n",
        "# CropAndResizeDataset(\"helen/helen68_train.csv\", \"helen/trainset/\", \"helen/cropped2helen/trainset/\", \"helen/cropped2helen_train.csv\")\n",
        "# CropAndResizeDataset(\"helen/helen68_test.csv\", \"helen/testset/\", \"helen/cropped2helen/testset/\", \"helen/cropped2helen_test.csv\")\n",
        "                     \n",
        "# CropAndResizeDataset(\"afw/afw_train.csv\", \"afw/trainset/\", \"afw/cropped2afw/trainset/\", \"afw/cropped2afw_train.csv\")\n",
        "# CropAndResizeDataset(\"afw/afw_test.csv\", \"afw/testset/\", \"afw/cropped2afw/testset/\", \"afw/cropped2afw_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvpW-TfW8hO7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('combined2/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show example from training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6FA2WzRF6ta"
      },
      "outputs": [],
      "source": [
        "imgname = '1002681492_1.jpg'\n",
        "landmarks= ast.literal_eval(df.loc[df['images'] == imgname].iloc[0]['landmarks'])\n",
        "img = cv2.imread('combined/trainset/'+imgname)\n",
        "for i in range(0,68):\n",
        "  cv2.circle(img, (landmarks[i][0],landmarks[i][1]), 2, (0, 255, 0), -1)\n",
        "\n",
        "\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#show image with matplotlib and increase figure size\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelspath = 'models/model63'\n",
        "loadedregressors = []\n",
        "loadedStandardModels = []\n",
        "loadedPCAModels = []\n",
        "for index in range(0,9):\n",
        "    filename = modelspath+'/regressor'+str(index)+'.pkl'\n",
        "    loadedregressors.append(joblib.load(filename))\n",
        "\n",
        "for index in range(0,3):\n",
        "    filename = modelspath+'/scaler'+str(index)+'.pkl'\n",
        "    loadedStandardModels.append(joblib.load(filename))\n",
        "\n",
        "for index in range(0,3):\n",
        "    filename = modelspath+'/pca'+str(index)+'.pkl'\n",
        "    loadedPCAModels.append(joblib.load(filename))\n",
        "initial_prediction = np.load(modelspath+'/mean_shape.npz')['shape']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imagesmodelshape = (200,200)\n",
        "\n",
        "#Read test image\n",
        "imgname = 'combined/testset/'+images_test[66]\n",
        "#imgname = 'randomimages/batman.png'\n",
        "#set initial shape to mean shape\n",
        "initial_prediction = initial_prediction.reshape(68,2).round().astype(int)\n",
        "\n",
        "#Read image\n",
        "img = cv2.imread(imgname)\n",
        "\n",
        "#resize image to (200,200)\n",
        "img = cv2.resize(img, imagesmodelshape)\n",
        "\n",
        "\n",
        "shape = initial_prediction\n",
        "#Predict offset from regressors\n",
        "\n",
        "shapesresults = []\n",
        "shapesresults.append(shape)\n",
        "for i in range (0, 3):\n",
        "    #hog_features = getHogFromLandmarks(shape, img)\n",
        "    hog_features = getHogFromLandmarks(shape, img)\n",
        "    offset = loadedregressors[i].predict([hog_features])\n",
        "    shape = shape + offset.reshape((68,2))\n",
        "    shape = shape.round().astype(int)\n",
        "    shapesresults.append(shape)\n",
        "\n",
        "for i in range (3, 6):\n",
        "    hog_features = getHogFromLandmarks(shape, img)\n",
        "    offset = loadedregressors[i].predict([hog_features])\n",
        "    shape = shape + offset.reshape((68,2))\n",
        "    shape = shape.round().astype(int)\n",
        "    shapesresults.append(shape)\n",
        "\n",
        "for i in range (6, 9):\n",
        "    sift_feutures = getSiftFromLandmarks(shape, img)\n",
        "    sift_features = loadedStandardModels[i-6].transform([sift_feutures])\n",
        "    pca_features = loadedPCAModels[i-6].transform(sift_features)\n",
        "    offset = loadedregressors[i].predict(pca_features)\n",
        "    shape = shape + offset.reshape((68,2))\n",
        "    shape = shape.round().astype(int)\n",
        "    shapesresults.append(shape)\n",
        "\n",
        "\n",
        "landmarks = shape\n",
        "\n",
        "for i in range(0,len(landmarks)):\n",
        "  cv2.circle(img, (landmarks[i][0],landmarks[i][1]), 3, (0, 255, 0), -1)\n",
        "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#show image with matplotlib and increase figure size\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# #saveimage\n",
        "os.makedirs('screens', exist_ok=True)\n",
        "l = len(os.listdir('screens'))\n",
        "cv2.imwrite('screens/'+str(l)+'.jpg', img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for shape in shapesresults: \n",
        "    landmarks = shape\n",
        "\n",
        "    image = cv2.resize(cv2.imread('Untitled.png'), (200,200))\n",
        "\n",
        "    for i in range(0,68):\n",
        "        cv2.circle(image, (landmarks[i][0],landmarks[i][1]), 3, (0, 0, 255), -1)\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#imgname = 'randomimages/test.jpg'\n",
        "#imgname = 'datasets68/croppedHelen68_200/testset/'+images_test[299]\n",
        "imgname = 'ada.jpg'\n",
        "\n",
        "img = cv2.imread(imgname)\n",
        "#copiedimg = cv2.resize(copiedimg, (200,200))\n",
        "\n",
        "faceLandmarksPredictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = cv2.imread(imgname, cv2.IMREAD_GRAYSCALE)\n",
        "plt.imshow(img, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "faceDetector = dlib.get_frontal_face_detector()\n",
        "face = faceDetector(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "landmarksd = faceLandmarksPredictor(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), face).parts()\n",
        "dlib_landmarks = []\n",
        "for p in landmarksd:\n",
        "    dlib_landmarks.append([p.x, p.y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(0,len(dlib_landmarks)):\n",
        "  cv2.circle(img, (dlib_landmarks[i][0],dlib_landmarks[i][1]), 3, (0, 255, 0), -1)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(copiedimg[face.top():face.bottom(), face.left():face.right()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from landmarks_detector import *\n",
        "from matplotlib import pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = cv2.imread('test.jpg')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "detector = LandmarksDetector(isPredictor=True, modelspath='models/model63/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "for i in range(0,100):\n",
        "    landmarks = detector.predict(gray, (500,1100,444,1080))\n",
        "end = time.time()\n",
        "\n",
        "#print in seconds\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(0,len(landmarks)):\n",
        "  cv2.circle(image, (landmarks[i][0],landmarks[i][1]), 5, (0, 255, 0), -1)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "faceLandmarksPredictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "#for i in range(100):\n",
        "landmarksd = faceLandmarksPredictor(gray,dlib.rectangle(520,1100,444,1080)).parts()\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "faceDetector = dlib.get_frontal_face_detector()\n",
        "face = faceDetector(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
